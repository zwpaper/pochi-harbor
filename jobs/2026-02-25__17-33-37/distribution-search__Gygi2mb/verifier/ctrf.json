{
    "results": {
        "tool": {
            "name": "pytest",
            "version": "8.4.1"
        },
        "summary": {
            "tests": 4,
            "passed": 0,
            "failed": 4,
            "skipped": 0,
            "pending": 0,
            "other": 0,
            "start": 1772013570.4858994,
            "stop": 1772013570.9893327
        },
        "tests": [
            {
                "name": "test_outputs.py::test_distribution_file_exists",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.000746600000638864,
                "start": 1772013570.8572464,
                "stop": 1772013570.9047563,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "def test_distribution_file_exists():\n        \"\"\"Test that the distribution file exists and can be loaded.\"\"\"\n        try:\n>           _ = np.load(\"/app/dist.npy\")\n                ^^^^^^^^^^^^^^^^^^^^^^^^\n\n/tests/test_outputs.py:27: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nfile = '/app/dist.npy', mmap_mode = None, allow_pickle = False\nfix_imports = True, encoding = 'ASCII'\n\n    @set_module('numpy')\n    def load(file, mmap_mode=None, allow_pickle=False, fix_imports=True,\n             encoding='ASCII', *, max_header_size=_MAX_HEADER_SIZE):\n        \"\"\"\n        Load arrays or pickled objects from ``.npy``, ``.npz`` or pickled files.\n    \n        .. warning:: Loading files that contain object arrays uses the ``pickle``\n                     module, which is not secure against erroneous or maliciously\n                     constructed data. Consider passing ``allow_pickle=False`` to\n                     load data that is known not to contain object arrays for the\n                     safer handling of untrusted sources.\n    \n        Parameters\n        ----------\n        file : file-like object, string, or pathlib.Path\n            The file to read. File-like objects must support the\n            ``seek()`` and ``read()`` methods and must always\n            be opened in binary mode.  Pickled files require that the\n            file-like object support the ``readline()`` method as well.\n        mmap_mode : {None, 'r+', 'r', 'w+', 'c'}, optional\n            If not None, then memory-map the file, using the given mode (see\n            `numpy.memmap` for a detailed description of the modes).  A\n            memory-mapped array is kept on disk. However, it can be accessed\n            and sliced like any ndarray.  Memory mapping is especially useful\n            for accessing small fragments of large files without reading the\n            entire file into memory.\n        allow_pickle : bool, optional\n            Allow loading pickled object arrays stored in npy files. Reasons for\n            disallowing pickles include security, as loading pickled data can\n            execute arbitrary code. If pickles are disallowed, loading object\n            arrays will fail. Default: False\n        fix_imports : bool, optional\n            Only useful when loading Python 2 generated pickled files,\n            which includes npy/npz files containing object arrays. If `fix_imports`\n            is True, pickle will try to map the old Python 2 names to the new names\n            used in Python 3.\n        encoding : str, optional\n            What encoding to use when reading Python 2 strings. Only useful when\n            loading Python 2 generated pickled files, which includes\n            npy/npz files containing object arrays. Values other than 'latin1',\n            'ASCII', and 'bytes' are not allowed, as they can corrupt numerical\n            data. Default: 'ASCII'\n        max_header_size : int, optional\n            Maximum allowed size of the header.  Large headers may not be safe\n            to load securely and thus require explicitly passing a larger value.\n            See :py:func:`ast.literal_eval()` for details.\n            This option is ignored when `allow_pickle` is passed.  In that case\n            the file is by definition trusted and the limit is unnecessary.\n    \n        Returns\n        -------\n        result : array, tuple, dict, etc.\n            Data stored in the file. For ``.npz`` files, the returned instance\n            of NpzFile class must be closed to avoid leaking file descriptors.\n    \n        Raises\n        ------\n        OSError\n            If the input file does not exist or cannot be read.\n        UnpicklingError\n            If ``allow_pickle=True``, but the file cannot be loaded as a pickle.\n        ValueError\n            The file contains an object array, but ``allow_pickle=False`` given.\n        EOFError\n            When calling ``np.load`` multiple times on the same file handle,\n            if all data has already been read\n    \n        See Also\n        --------\n        save, savez, savez_compressed, loadtxt\n        memmap : Create a memory-map to an array stored in a file on disk.\n        lib.format.open_memmap : Create or load a memory-mapped ``.npy`` file.\n    \n        Notes\n        -----\n        - If the file contains pickle data, then whatever object is stored\n          in the pickle is returned.\n        - If the file is a ``.npy`` file, then a single array is returned.\n        - If the file is a ``.npz`` file, then a dictionary-like object is\n          returned, containing ``{filename: array}`` key-value pairs, one for\n          each file in the archive.\n        - If the file is a ``.npz`` file, the returned value supports the\n          context manager protocol in a similar fashion to the open function::\n    \n            with load('foo.npz') as data:\n                a = data['a']\n    \n          The underlying file descriptor is closed when exiting the 'with'\n          block.\n    \n        Examples\n        --------\n        >>> import numpy as np\n    \n        Store data to disk, and load it again:\n    \n        >>> np.save('/tmp/123', np.array([[1, 2, 3], [4, 5, 6]]))\n        >>> np.load('/tmp/123.npy')\n        array([[1, 2, 3],\n               [4, 5, 6]])\n    \n        Store compressed data to disk, and load it again:\n    \n        >>> a=np.array([[1, 2, 3], [4, 5, 6]])\n        >>> b=np.array([1, 2])\n        >>> np.savez('/tmp/123.npz', a=a, b=b)\n        >>> data = np.load('/tmp/123.npz')\n        >>> data['a']\n        array([[1, 2, 3],\n               [4, 5, 6]])\n        >>> data['b']\n        array([1, 2])\n        >>> data.close()\n    \n        Mem-map the stored array, and then access the second row\n        directly from disk:\n    \n        >>> X = np.load('/tmp/123.npy', mmap_mode='r')\n        >>> X[1, :]\n        memmap([4, 5, 6])\n    \n        \"\"\"\n        if encoding not in ('ASCII', 'latin1', 'bytes'):\n            # The 'encoding' value for pickle also affects what encoding\n            # the serialized binary data of NumPy arrays is loaded\n            # in. Pickle does not pass on the encoding information to\n            # NumPy. The unpickling code in numpy._core.multiarray is\n            # written to assume that unicode data appearing where binary\n            # should be is in 'latin1'. 'bytes' is also safe, as is 'ASCII'.\n            #\n            # Other encoding values can corrupt binary data, and we\n            # purposefully disallow them. For the same reason, the errors=\n            # argument is not exposed, as values other than 'strict'\n            # result can similarly silently corrupt numerical data.\n            raise ValueError(\"encoding must be 'ASCII', 'latin1', or 'bytes'\")\n    \n        pickle_kwargs = {'encoding': encoding, 'fix_imports': fix_imports}\n    \n        with contextlib.ExitStack() as stack:\n            if hasattr(file, 'read'):\n                fid = file\n                own_fid = False\n            else:\n>               fid = stack.enter_context(open(os.fspath(file), \"rb\"))\n                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE               FileNotFoundError: [Errno 2] No such file or directory: '/app/dist.npy'\n\n/root/.cache/uv/archive-v0/zSlKqJujUhbMoc2l7_IV3/lib/python3.13/site-packages/numpy/lib/_npyio_impl.py:454: FileNotFoundError\n\nDuring handling of the above exception, another exception occurred:\n\n    def test_distribution_file_exists():\n        \"\"\"Test that the distribution file exists and can be loaded.\"\"\"\n        try:\n            _ = np.load(\"/app/dist.npy\")\n        except FileNotFoundError:\n>           pytest.fail(\"Distribution file /app/dist.npy not found\")\nE           Failed: Distribution file /app/dist.npy not found\n\n/tests/test_outputs.py:29: Failed",
                "message": "The test failed in the call phase"
            },
            {
                "name": "test_outputs.py::test_distribution_shape",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.0007606919989484595,
                "start": 1772013570.9052513,
                "stop": 1772013570.9378915,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "def test_distribution_shape():\n        \"\"\"Test distribution has correct shape and data type.\"\"\"\n>       P = np.load(\"/app/dist.npy\")\n            ^^^^^^^^^^^^^^^^^^^^^^^^\n\n/tests/test_outputs.py:36: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nfile = '/app/dist.npy', mmap_mode = None, allow_pickle = False\nfix_imports = True, encoding = 'ASCII'\n\n    @set_module('numpy')\n    def load(file, mmap_mode=None, allow_pickle=False, fix_imports=True,\n             encoding='ASCII', *, max_header_size=_MAX_HEADER_SIZE):\n        \"\"\"\n        Load arrays or pickled objects from ``.npy``, ``.npz`` or pickled files.\n    \n        .. warning:: Loading files that contain object arrays uses the ``pickle``\n                     module, which is not secure against erroneous or maliciously\n                     constructed data. Consider passing ``allow_pickle=False`` to\n                     load data that is known not to contain object arrays for the\n                     safer handling of untrusted sources.\n    \n        Parameters\n        ----------\n        file : file-like object, string, or pathlib.Path\n            The file to read. File-like objects must support the\n            ``seek()`` and ``read()`` methods and must always\n            be opened in binary mode.  Pickled files require that the\n            file-like object support the ``readline()`` method as well.\n        mmap_mode : {None, 'r+', 'r', 'w+', 'c'}, optional\n            If not None, then memory-map the file, using the given mode (see\n            `numpy.memmap` for a detailed description of the modes).  A\n            memory-mapped array is kept on disk. However, it can be accessed\n            and sliced like any ndarray.  Memory mapping is especially useful\n            for accessing small fragments of large files without reading the\n            entire file into memory.\n        allow_pickle : bool, optional\n            Allow loading pickled object arrays stored in npy files. Reasons for\n            disallowing pickles include security, as loading pickled data can\n            execute arbitrary code. If pickles are disallowed, loading object\n            arrays will fail. Default: False\n        fix_imports : bool, optional\n            Only useful when loading Python 2 generated pickled files,\n            which includes npy/npz files containing object arrays. If `fix_imports`\n            is True, pickle will try to map the old Python 2 names to the new names\n            used in Python 3.\n        encoding : str, optional\n            What encoding to use when reading Python 2 strings. Only useful when\n            loading Python 2 generated pickled files, which includes\n            npy/npz files containing object arrays. Values other than 'latin1',\n            'ASCII', and 'bytes' are not allowed, as they can corrupt numerical\n            data. Default: 'ASCII'\n        max_header_size : int, optional\n            Maximum allowed size of the header.  Large headers may not be safe\n            to load securely and thus require explicitly passing a larger value.\n            See :py:func:`ast.literal_eval()` for details.\n            This option is ignored when `allow_pickle` is passed.  In that case\n            the file is by definition trusted and the limit is unnecessary.\n    \n        Returns\n        -------\n        result : array, tuple, dict, etc.\n            Data stored in the file. For ``.npz`` files, the returned instance\n            of NpzFile class must be closed to avoid leaking file descriptors.\n    \n        Raises\n        ------\n        OSError\n            If the input file does not exist or cannot be read.\n        UnpicklingError\n            If ``allow_pickle=True``, but the file cannot be loaded as a pickle.\n        ValueError\n            The file contains an object array, but ``allow_pickle=False`` given.\n        EOFError\n            When calling ``np.load`` multiple times on the same file handle,\n            if all data has already been read\n    \n        See Also\n        --------\n        save, savez, savez_compressed, loadtxt\n        memmap : Create a memory-map to an array stored in a file on disk.\n        lib.format.open_memmap : Create or load a memory-mapped ``.npy`` file.\n    \n        Notes\n        -----\n        - If the file contains pickle data, then whatever object is stored\n          in the pickle is returned.\n        - If the file is a ``.npy`` file, then a single array is returned.\n        - If the file is a ``.npz`` file, then a dictionary-like object is\n          returned, containing ``{filename: array}`` key-value pairs, one for\n          each file in the archive.\n        - If the file is a ``.npz`` file, the returned value supports the\n          context manager protocol in a similar fashion to the open function::\n    \n            with load('foo.npz') as data:\n                a = data['a']\n    \n          The underlying file descriptor is closed when exiting the 'with'\n          block.\n    \n        Examples\n        --------\n        >>> import numpy as np\n    \n        Store data to disk, and load it again:\n    \n        >>> np.save('/tmp/123', np.array([[1, 2, 3], [4, 5, 6]]))\n        >>> np.load('/tmp/123.npy')\n        array([[1, 2, 3],\n               [4, 5, 6]])\n    \n        Store compressed data to disk, and load it again:\n    \n        >>> a=np.array([[1, 2, 3], [4, 5, 6]])\n        >>> b=np.array([1, 2])\n        >>> np.savez('/tmp/123.npz', a=a, b=b)\n        >>> data = np.load('/tmp/123.npz')\n        >>> data['a']\n        array([[1, 2, 3],\n               [4, 5, 6]])\n        >>> data['b']\n        array([1, 2])\n        >>> data.close()\n    \n        Mem-map the stored array, and then access the second row\n        directly from disk:\n    \n        >>> X = np.load('/tmp/123.npy', mmap_mode='r')\n        >>> X[1, :]\n        memmap([4, 5, 6])\n    \n        \"\"\"\n        if encoding not in ('ASCII', 'latin1', 'bytes'):\n            # The 'encoding' value for pickle also affects what encoding\n            # the serialized binary data of NumPy arrays is loaded\n            # in. Pickle does not pass on the encoding information to\n            # NumPy. The unpickling code in numpy._core.multiarray is\n            # written to assume that unicode data appearing where binary\n            # should be is in 'latin1'. 'bytes' is also safe, as is 'ASCII'.\n            #\n            # Other encoding values can corrupt binary data, and we\n            # purposefully disallow them. For the same reason, the errors=\n            # argument is not exposed, as values other than 'strict'\n            # result can similarly silently corrupt numerical data.\n            raise ValueError(\"encoding must be 'ASCII', 'latin1', or 'bytes'\")\n    \n        pickle_kwargs = {'encoding': encoding, 'fix_imports': fix_imports}\n    \n        with contextlib.ExitStack() as stack:\n            if hasattr(file, 'read'):\n                fid = file\n                own_fid = False\n            else:\n>               fid = stack.enter_context(open(os.fspath(file), \"rb\"))\n                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE               FileNotFoundError: [Errno 2] No such file or directory: '/app/dist.npy'\n\n/root/.cache/uv/archive-v0/zSlKqJujUhbMoc2l7_IV3/lib/python3.13/site-packages/numpy/lib/_npyio_impl.py:454: FileNotFoundError",
                "message": "The test failed in the call phase"
            },
            {
                "name": "test_outputs.py::test_distribution_validity",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.0006316170010904898,
                "start": 1772013570.938304,
                "stop": 1772013570.9649222,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "def test_distribution_validity():\n        \"\"\"Test that the distribution is a valid probability distribution.\"\"\"\n>       P = np.load(\"/app/dist.npy\")\n            ^^^^^^^^^^^^^^^^^^^^^^^^\n\n/tests/test_outputs.py:49: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nfile = '/app/dist.npy', mmap_mode = None, allow_pickle = False\nfix_imports = True, encoding = 'ASCII'\n\n    @set_module('numpy')\n    def load(file, mmap_mode=None, allow_pickle=False, fix_imports=True,\n             encoding='ASCII', *, max_header_size=_MAX_HEADER_SIZE):\n        \"\"\"\n        Load arrays or pickled objects from ``.npy``, ``.npz`` or pickled files.\n    \n        .. warning:: Loading files that contain object arrays uses the ``pickle``\n                     module, which is not secure against erroneous or maliciously\n                     constructed data. Consider passing ``allow_pickle=False`` to\n                     load data that is known not to contain object arrays for the\n                     safer handling of untrusted sources.\n    \n        Parameters\n        ----------\n        file : file-like object, string, or pathlib.Path\n            The file to read. File-like objects must support the\n            ``seek()`` and ``read()`` methods and must always\n            be opened in binary mode.  Pickled files require that the\n            file-like object support the ``readline()`` method as well.\n        mmap_mode : {None, 'r+', 'r', 'w+', 'c'}, optional\n            If not None, then memory-map the file, using the given mode (see\n            `numpy.memmap` for a detailed description of the modes).  A\n            memory-mapped array is kept on disk. However, it can be accessed\n            and sliced like any ndarray.  Memory mapping is especially useful\n            for accessing small fragments of large files without reading the\n            entire file into memory.\n        allow_pickle : bool, optional\n            Allow loading pickled object arrays stored in npy files. Reasons for\n            disallowing pickles include security, as loading pickled data can\n            execute arbitrary code. If pickles are disallowed, loading object\n            arrays will fail. Default: False\n        fix_imports : bool, optional\n            Only useful when loading Python 2 generated pickled files,\n            which includes npy/npz files containing object arrays. If `fix_imports`\n            is True, pickle will try to map the old Python 2 names to the new names\n            used in Python 3.\n        encoding : str, optional\n            What encoding to use when reading Python 2 strings. Only useful when\n            loading Python 2 generated pickled files, which includes\n            npy/npz files containing object arrays. Values other than 'latin1',\n            'ASCII', and 'bytes' are not allowed, as they can corrupt numerical\n            data. Default: 'ASCII'\n        max_header_size : int, optional\n            Maximum allowed size of the header.  Large headers may not be safe\n            to load securely and thus require explicitly passing a larger value.\n            See :py:func:`ast.literal_eval()` for details.\n            This option is ignored when `allow_pickle` is passed.  In that case\n            the file is by definition trusted and the limit is unnecessary.\n    \n        Returns\n        -------\n        result : array, tuple, dict, etc.\n            Data stored in the file. For ``.npz`` files, the returned instance\n            of NpzFile class must be closed to avoid leaking file descriptors.\n    \n        Raises\n        ------\n        OSError\n            If the input file does not exist or cannot be read.\n        UnpicklingError\n            If ``allow_pickle=True``, but the file cannot be loaded as a pickle.\n        ValueError\n            The file contains an object array, but ``allow_pickle=False`` given.\n        EOFError\n            When calling ``np.load`` multiple times on the same file handle,\n            if all data has already been read\n    \n        See Also\n        --------\n        save, savez, savez_compressed, loadtxt\n        memmap : Create a memory-map to an array stored in a file on disk.\n        lib.format.open_memmap : Create or load a memory-mapped ``.npy`` file.\n    \n        Notes\n        -----\n        - If the file contains pickle data, then whatever object is stored\n          in the pickle is returned.\n        - If the file is a ``.npy`` file, then a single array is returned.\n        - If the file is a ``.npz`` file, then a dictionary-like object is\n          returned, containing ``{filename: array}`` key-value pairs, one for\n          each file in the archive.\n        - If the file is a ``.npz`` file, the returned value supports the\n          context manager protocol in a similar fashion to the open function::\n    \n            with load('foo.npz') as data:\n                a = data['a']\n    \n          The underlying file descriptor is closed when exiting the 'with'\n          block.\n    \n        Examples\n        --------\n        >>> import numpy as np\n    \n        Store data to disk, and load it again:\n    \n        >>> np.save('/tmp/123', np.array([[1, 2, 3], [4, 5, 6]]))\n        >>> np.load('/tmp/123.npy')\n        array([[1, 2, 3],\n               [4, 5, 6]])\n    \n        Store compressed data to disk, and load it again:\n    \n        >>> a=np.array([[1, 2, 3], [4, 5, 6]])\n        >>> b=np.array([1, 2])\n        >>> np.savez('/tmp/123.npz', a=a, b=b)\n        >>> data = np.load('/tmp/123.npz')\n        >>> data['a']\n        array([[1, 2, 3],\n               [4, 5, 6]])\n        >>> data['b']\n        array([1, 2])\n        >>> data.close()\n    \n        Mem-map the stored array, and then access the second row\n        directly from disk:\n    \n        >>> X = np.load('/tmp/123.npy', mmap_mode='r')\n        >>> X[1, :]\n        memmap([4, 5, 6])\n    \n        \"\"\"\n        if encoding not in ('ASCII', 'latin1', 'bytes'):\n            # The 'encoding' value for pickle also affects what encoding\n            # the serialized binary data of NumPy arrays is loaded\n            # in. Pickle does not pass on the encoding information to\n            # NumPy. The unpickling code in numpy._core.multiarray is\n            # written to assume that unicode data appearing where binary\n            # should be is in 'latin1'. 'bytes' is also safe, as is 'ASCII'.\n            #\n            # Other encoding values can corrupt binary data, and we\n            # purposefully disallow them. For the same reason, the errors=\n            # argument is not exposed, as values other than 'strict'\n            # result can similarly silently corrupt numerical data.\n            raise ValueError(\"encoding must be 'ASCII', 'latin1', or 'bytes'\")\n    \n        pickle_kwargs = {'encoding': encoding, 'fix_imports': fix_imports}\n    \n        with contextlib.ExitStack() as stack:\n            if hasattr(file, 'read'):\n                fid = file\n                own_fid = False\n            else:\n>               fid = stack.enter_context(open(os.fspath(file), \"rb\"))\n                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE               FileNotFoundError: [Errno 2] No such file or directory: '/app/dist.npy'\n\n/root/.cache/uv/archive-v0/zSlKqJujUhbMoc2l7_IV3/lib/python3.13/site-packages/numpy/lib/_npyio_impl.py:454: FileNotFoundError",
                "message": "The test failed in the call phase"
            },
            {
                "name": "test_outputs.py::test_kl_divergences",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.0006601029990633833,
                "start": 1772013570.9652212,
                "stop": 1772013570.9891686,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "def test_kl_divergences():\n        \"\"\"Test that KL divergences meet the target requirements.\"\"\"\n>       P = np.load(\"/app/dist.npy\")\n            ^^^^^^^^^^^^^^^^^^^^^^^^\n\n/tests/test_outputs.py:69: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nfile = '/app/dist.npy', mmap_mode = None, allow_pickle = False\nfix_imports = True, encoding = 'ASCII'\n\n    @set_module('numpy')\n    def load(file, mmap_mode=None, allow_pickle=False, fix_imports=True,\n             encoding='ASCII', *, max_header_size=_MAX_HEADER_SIZE):\n        \"\"\"\n        Load arrays or pickled objects from ``.npy``, ``.npz`` or pickled files.\n    \n        .. warning:: Loading files that contain object arrays uses the ``pickle``\n                     module, which is not secure against erroneous or maliciously\n                     constructed data. Consider passing ``allow_pickle=False`` to\n                     load data that is known not to contain object arrays for the\n                     safer handling of untrusted sources.\n    \n        Parameters\n        ----------\n        file : file-like object, string, or pathlib.Path\n            The file to read. File-like objects must support the\n            ``seek()`` and ``read()`` methods and must always\n            be opened in binary mode.  Pickled files require that the\n            file-like object support the ``readline()`` method as well.\n        mmap_mode : {None, 'r+', 'r', 'w+', 'c'}, optional\n            If not None, then memory-map the file, using the given mode (see\n            `numpy.memmap` for a detailed description of the modes).  A\n            memory-mapped array is kept on disk. However, it can be accessed\n            and sliced like any ndarray.  Memory mapping is especially useful\n            for accessing small fragments of large files without reading the\n            entire file into memory.\n        allow_pickle : bool, optional\n            Allow loading pickled object arrays stored in npy files. Reasons for\n            disallowing pickles include security, as loading pickled data can\n            execute arbitrary code. If pickles are disallowed, loading object\n            arrays will fail. Default: False\n        fix_imports : bool, optional\n            Only useful when loading Python 2 generated pickled files,\n            which includes npy/npz files containing object arrays. If `fix_imports`\n            is True, pickle will try to map the old Python 2 names to the new names\n            used in Python 3.\n        encoding : str, optional\n            What encoding to use when reading Python 2 strings. Only useful when\n            loading Python 2 generated pickled files, which includes\n            npy/npz files containing object arrays. Values other than 'latin1',\n            'ASCII', and 'bytes' are not allowed, as they can corrupt numerical\n            data. Default: 'ASCII'\n        max_header_size : int, optional\n            Maximum allowed size of the header.  Large headers may not be safe\n            to load securely and thus require explicitly passing a larger value.\n            See :py:func:`ast.literal_eval()` for details.\n            This option is ignored when `allow_pickle` is passed.  In that case\n            the file is by definition trusted and the limit is unnecessary.\n    \n        Returns\n        -------\n        result : array, tuple, dict, etc.\n            Data stored in the file. For ``.npz`` files, the returned instance\n            of NpzFile class must be closed to avoid leaking file descriptors.\n    \n        Raises\n        ------\n        OSError\n            If the input file does not exist or cannot be read.\n        UnpicklingError\n            If ``allow_pickle=True``, but the file cannot be loaded as a pickle.\n        ValueError\n            The file contains an object array, but ``allow_pickle=False`` given.\n        EOFError\n            When calling ``np.load`` multiple times on the same file handle,\n            if all data has already been read\n    \n        See Also\n        --------\n        save, savez, savez_compressed, loadtxt\n        memmap : Create a memory-map to an array stored in a file on disk.\n        lib.format.open_memmap : Create or load a memory-mapped ``.npy`` file.\n    \n        Notes\n        -----\n        - If the file contains pickle data, then whatever object is stored\n          in the pickle is returned.\n        - If the file is a ``.npy`` file, then a single array is returned.\n        - If the file is a ``.npz`` file, then a dictionary-like object is\n          returned, containing ``{filename: array}`` key-value pairs, one for\n          each file in the archive.\n        - If the file is a ``.npz`` file, the returned value supports the\n          context manager protocol in a similar fashion to the open function::\n    \n            with load('foo.npz') as data:\n                a = data['a']\n    \n          The underlying file descriptor is closed when exiting the 'with'\n          block.\n    \n        Examples\n        --------\n        >>> import numpy as np\n    \n        Store data to disk, and load it again:\n    \n        >>> np.save('/tmp/123', np.array([[1, 2, 3], [4, 5, 6]]))\n        >>> np.load('/tmp/123.npy')\n        array([[1, 2, 3],\n               [4, 5, 6]])\n    \n        Store compressed data to disk, and load it again:\n    \n        >>> a=np.array([[1, 2, 3], [4, 5, 6]])\n        >>> b=np.array([1, 2])\n        >>> np.savez('/tmp/123.npz', a=a, b=b)\n        >>> data = np.load('/tmp/123.npz')\n        >>> data['a']\n        array([[1, 2, 3],\n               [4, 5, 6]])\n        >>> data['b']\n        array([1, 2])\n        >>> data.close()\n    \n        Mem-map the stored array, and then access the second row\n        directly from disk:\n    \n        >>> X = np.load('/tmp/123.npy', mmap_mode='r')\n        >>> X[1, :]\n        memmap([4, 5, 6])\n    \n        \"\"\"\n        if encoding not in ('ASCII', 'latin1', 'bytes'):\n            # The 'encoding' value for pickle also affects what encoding\n            # the serialized binary data of NumPy arrays is loaded\n            # in. Pickle does not pass on the encoding information to\n            # NumPy. The unpickling code in numpy._core.multiarray is\n            # written to assume that unicode data appearing where binary\n            # should be is in 'latin1'. 'bytes' is also safe, as is 'ASCII'.\n            #\n            # Other encoding values can corrupt binary data, and we\n            # purposefully disallow them. For the same reason, the errors=\n            # argument is not exposed, as values other than 'strict'\n            # result can similarly silently corrupt numerical data.\n            raise ValueError(\"encoding must be 'ASCII', 'latin1', or 'bytes'\")\n    \n        pickle_kwargs = {'encoding': encoding, 'fix_imports': fix_imports}\n    \n        with contextlib.ExitStack() as stack:\n            if hasattr(file, 'read'):\n                fid = file\n                own_fid = False\n            else:\n>               fid = stack.enter_context(open(os.fspath(file), \"rb\"))\n                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE               FileNotFoundError: [Errno 2] No such file or directory: '/app/dist.npy'\n\n/root/.cache/uv/archive-v0/zSlKqJujUhbMoc2l7_IV3/lib/python3.13/site-packages/numpy/lib/_npyio_impl.py:454: FileNotFoundError",
                "message": "The test failed in the call phase"
            }
        ]
    }
}