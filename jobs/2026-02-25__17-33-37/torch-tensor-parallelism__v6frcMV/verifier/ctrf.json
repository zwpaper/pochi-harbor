{
    "results": {
        "tool": {
            "name": "pytest",
            "version": "8.4.1"
        },
        "summary": {
            "tests": 3,
            "passed": 0,
            "failed": 3,
            "skipped": 0,
            "pending": 0,
            "other": 0,
            "start": 1772013367.5711234,
            "stop": 1772013448.9069471
        },
        "tests": [
            {
                "name": "test_outputs.py::test_parallel_linear_exists",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.000884297999618866,
                "start": 1772013374.869852,
                "stop": 1772013374.8747559,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "def test_parallel_linear_exists():\n        \"\"\"\n        Checks that the agent creates a file named parallel_linear.py\n        in the expected directory.\n        \"\"\"\n        parallel_linear_path = Path(\"/app/parallel_linear.py\")\n    \n>       assert parallel_linear_path.exists(), f\"File {parallel_linear_path} does not exist\"\nE       AssertionError: File /app/parallel_linear.py does not exist\nE       assert False\nE        +  where False = exists()\nE        +    where exists = PosixPath('/app/parallel_linear.py').exists\n\n/tests/test_outputs.py:25: AssertionError",
                "message": "The test failed in the call phase due to an assertion error"
            },
            {
                "name": "test_outputs.py::test_column_parallel_linear",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 2.014708805000737,
                "start": 1772013374.8749774,
                "stop": 1772013376.9055665,
                "retries": 5,
                "file_path": "test_outputs.py",
                "tags": [
                    "parametrize::world_size::[1, 2, 4]",
                    "parametrize::bias::[True, False]"
                ],
                "trace": "bias = False, world_size = 4\n\n    @pytest.mark.parametrize(\"bias\", [True, False])\n    @pytest.mark.parametrize(\"world_size\", [1, 2, 4])\n    def test_column_parallel_linear(bias, world_size):\n        \"\"\"\n        Checks that ColumnParallelLinear slices weights and bias correctly,\n        and produces correct output and gradients for different world sizes\n        and bias settings.\n        \"\"\"\n>       mp.spawn(\n            _test_column_parallel_linear,\n            args=(world_size, bias),\n            nprocs=world_size,\n            join=True,\n        )\n\n/tests/test_outputs.py:193: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/root/.cache/uv/archive-v0/aTZRZY5bLGLtE1YxwfdWP/lib/python3.13/site-packages/torch/multiprocessing/spawn.py:340: in spawn\n    return start_processes(fn, args, nprocs, join, daemon, start_method=\"spawn\")\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/root/.cache/uv/archive-v0/aTZRZY5bLGLtE1YxwfdWP/lib/python3.13/site-packages/torch/multiprocessing/spawn.py:296: in start_processes\n    while not context.join():\n              ^^^^^^^^^^^^^^\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <torch.multiprocessing.spawn.ProcessContext object at 0x756d82a16d50>\ntimeout = None, grace_period = None\n\n    def join(\n        self, timeout: Optional[float] = None, grace_period: Optional[float] = None\n    ):\n        r\"\"\"Join one or more processes within spawn context.\n    \n        Attempt to join one or more processes in this spawn context.\n        If one of them exited with a non-zero exit status, this function\n        kills the remaining processes (optionally with a grace period)\n        and raises an exception with the cause of the first process exiting.\n    \n        Returns ``True`` if all processes have been joined successfully,\n        ``False`` if there are more processes that need to be joined.\n    \n        Args:\n            timeout (float): Wait this long (in seconds) before giving up on waiting.\n            grace_period (float): When any processes fail, wait this long (in seconds)\n                for others to shutdown gracefully before terminating them. If they\n                still don't exit, wait another grace period before killing them.\n        \"\"\"\n        # Ensure this function can be called even when we're done.\n        if len(self.sentinels) == 0:\n            return True\n    \n        # Wait for any process to fail or all of them to succeed.\n        ready = multiprocessing.connection.wait(\n            self.sentinels.keys(),\n            timeout=timeout,\n        )\n    \n        error_index = None\n        for sentinel in ready:\n            index = self.sentinels.pop(sentinel)\n            process = self.processes[index]\n            process.join()\n            if process.exitcode != 0:\n                error_index = index\n                break\n    \n        # Return if there was no error.\n        if error_index is None:\n            # Return whether or not all processes have been joined.\n            return len(self.sentinels) == 0\n        # An error occurred. Clean-up all processes before returning.\n        # First, allow a grace period for processes to shutdown themselves.\n        if grace_period is not None:\n            self._join_procs_with_timeout(grace_period)\n        # Then, terminate processes that are still alive. Try SIGTERM first.\n        for process in self.processes:\n            if process.is_alive():\n                log.warning(\"Terminating process %s via signal SIGTERM\", process.pid)\n                process.terminate()\n    \n        # Try SIGKILL if the process isn't going down after another grace_period.\n        # The reason is related to python signal handling is limited\n        # to main thread and if that is in c/c++ land and stuck it won't\n        # to handle it. We have seen processes getting stuck not handling\n        # SIGTERM for the above reason.\n        self._join_procs_with_timeout(30 if grace_period is None else grace_period)\n        for process in self.processes:\n            if process.is_alive():\n                log.warning(\n                    \"Unable to shutdown process %s via SIGTERM , forcefully exiting via SIGKILL\",\n                    process.pid,\n                )\n                process.kill()\n            process.join()\n    \n        # The file will only be created if the process crashed.\n        failed_process = self.processes[error_index]\n        if not os.access(self.error_files[error_index], os.R_OK):\n            exitcode = self.processes[error_index].exitcode\n            if exitcode < 0:\n                try:\n                    name = signal.Signals(-exitcode).name\n                except ValueError:\n                    name = f\"<Unknown signal {-exitcode}>\"\n                raise ProcessExitedException(\n                    f\"process {error_index:d} terminated with signal {name}\",\n                    error_index=error_index,\n                    error_pid=failed_process.pid,\n                    exit_code=exitcode,\n                    signal_name=name,\n                )\n            else:\n                raise ProcessExitedException(\n                    f\"process {error_index:d} terminated with exit code {exitcode:d}\",\n                    error_index=error_index,\n                    error_pid=failed_process.pid,\n                    exit_code=exitcode,\n                )\n    \n        with open(self.error_files[error_index], \"rb\") as fh:\n            original_trace = pickle.load(fh)\n        msg = f\"\\n\\n-- Process {error_index:d} terminated with the following error:\\n\"\n        msg += original_trace\n>       raise ProcessRaisedException(msg, error_index, failed_process.pid)\nE       torch.multiprocessing.spawn.ProcessRaisedException: \nE       \nE       -- Process 0 terminated with the following error:\nE       Traceback (most recent call last):\nE         File \"/root/.cache/uv/archive-v0/aTZRZY5bLGLtE1YxwfdWP/lib/python3.13/site-packages/torch/multiprocessing/spawn.py\", line 90, in _wrap\nE           fn(i, *args)\nE           ~~^^^^^^^^^^\nE         File \"/tests/test_outputs.py\", line 46, in _test_column_parallel_linear\nE           from parallel_linear import ColumnParallelLinear\nE       ModuleNotFoundError: No module named 'parallel_linear'\n\n/root/.cache/uv/archive-v0/aTZRZY5bLGLtE1YxwfdWP/lib/python3.13/site-packages/torch/multiprocessing/spawn.py:215: ProcessRaisedException",
                "message": "The test failed in the call phase due to an exception"
            },
            {
                "name": "test_outputs.py::test_row_parallel_linear",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 1.6983249480017548,
                "start": 1772013415.540159,
                "stop": 1772013417.2497978,
                "retries": 5,
                "file_path": "test_outputs.py",
                "tags": [
                    "parametrize::world_size::[1, 2, 4]",
                    "parametrize::bias::[True, False]"
                ],
                "trace": "bias = False, world_size = 4\n\n    @pytest.mark.parametrize(\"bias\", [True, False])\n    @pytest.mark.parametrize(\"world_size\", [1, 2, 4])\n    def test_row_parallel_linear(bias, world_size):\n        \"\"\"\n        Checks that RowParallelLinear slices weights and bias correctly,\n        and produces correct output and gradients for different world sizes\n        and bias settings.\n        \"\"\"\n>       mp.spawn(\n            _test_row_parallel_linear, args=(world_size, bias), nprocs=world_size, join=True\n        )\n\n/tests/test_outputs.py:209: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/root/.cache/uv/archive-v0/aTZRZY5bLGLtE1YxwfdWP/lib/python3.13/site-packages/torch/multiprocessing/spawn.py:340: in spawn\n    return start_processes(fn, args, nprocs, join, daemon, start_method=\"spawn\")\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/root/.cache/uv/archive-v0/aTZRZY5bLGLtE1YxwfdWP/lib/python3.13/site-packages/torch/multiprocessing/spawn.py:296: in start_processes\n    while not context.join():\n              ^^^^^^^^^^^^^^\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <torch.multiprocessing.spawn.ProcessContext object at 0x756d82898320>\ntimeout = None, grace_period = None\n\n    def join(\n        self, timeout: Optional[float] = None, grace_period: Optional[float] = None\n    ):\n        r\"\"\"Join one or more processes within spawn context.\n    \n        Attempt to join one or more processes in this spawn context.\n        If one of them exited with a non-zero exit status, this function\n        kills the remaining processes (optionally with a grace period)\n        and raises an exception with the cause of the first process exiting.\n    \n        Returns ``True`` if all processes have been joined successfully,\n        ``False`` if there are more processes that need to be joined.\n    \n        Args:\n            timeout (float): Wait this long (in seconds) before giving up on waiting.\n            grace_period (float): When any processes fail, wait this long (in seconds)\n                for others to shutdown gracefully before terminating them. If they\n                still don't exit, wait another grace period before killing them.\n        \"\"\"\n        # Ensure this function can be called even when we're done.\n        if len(self.sentinels) == 0:\n            return True\n    \n        # Wait for any process to fail or all of them to succeed.\n        ready = multiprocessing.connection.wait(\n            self.sentinels.keys(),\n            timeout=timeout,\n        )\n    \n        error_index = None\n        for sentinel in ready:\n            index = self.sentinels.pop(sentinel)\n            process = self.processes[index]\n            process.join()\n            if process.exitcode != 0:\n                error_index = index\n                break\n    \n        # Return if there was no error.\n        if error_index is None:\n            # Return whether or not all processes have been joined.\n            return len(self.sentinels) == 0\n        # An error occurred. Clean-up all processes before returning.\n        # First, allow a grace period for processes to shutdown themselves.\n        if grace_period is not None:\n            self._join_procs_with_timeout(grace_period)\n        # Then, terminate processes that are still alive. Try SIGTERM first.\n        for process in self.processes:\n            if process.is_alive():\n                log.warning(\"Terminating process %s via signal SIGTERM\", process.pid)\n                process.terminate()\n    \n        # Try SIGKILL if the process isn't going down after another grace_period.\n        # The reason is related to python signal handling is limited\n        # to main thread and if that is in c/c++ land and stuck it won't\n        # to handle it. We have seen processes getting stuck not handling\n        # SIGTERM for the above reason.\n        self._join_procs_with_timeout(30 if grace_period is None else grace_period)\n        for process in self.processes:\n            if process.is_alive():\n                log.warning(\n                    \"Unable to shutdown process %s via SIGTERM , forcefully exiting via SIGKILL\",\n                    process.pid,\n                )\n                process.kill()\n            process.join()\n    \n        # The file will only be created if the process crashed.\n        failed_process = self.processes[error_index]\n        if not os.access(self.error_files[error_index], os.R_OK):\n            exitcode = self.processes[error_index].exitcode\n            if exitcode < 0:\n                try:\n                    name = signal.Signals(-exitcode).name\n                except ValueError:\n                    name = f\"<Unknown signal {-exitcode}>\"\n                raise ProcessExitedException(\n                    f\"process {error_index:d} terminated with signal {name}\",\n                    error_index=error_index,\n                    error_pid=failed_process.pid,\n                    exit_code=exitcode,\n                    signal_name=name,\n                )\n            else:\n                raise ProcessExitedException(\n                    f\"process {error_index:d} terminated with exit code {exitcode:d}\",\n                    error_index=error_index,\n                    error_pid=failed_process.pid,\n                    exit_code=exitcode,\n                )\n    \n        with open(self.error_files[error_index], \"rb\") as fh:\n            original_trace = pickle.load(fh)\n        msg = f\"\\n\\n-- Process {error_index:d} terminated with the following error:\\n\"\n        msg += original_trace\n>       raise ProcessRaisedException(msg, error_index, failed_process.pid)\nE       torch.multiprocessing.spawn.ProcessRaisedException: \nE       \nE       -- Process 3 terminated with the following error:\nE       Traceback (most recent call last):\nE         File \"/root/.cache/uv/archive-v0/aTZRZY5bLGLtE1YxwfdWP/lib/python3.13/site-packages/torch/multiprocessing/spawn.py\", line 90, in _wrap\nE           fn(i, *args)\nE           ~~^^^^^^^^^^\nE         File \"/tests/test_outputs.py\", line 115, in _test_row_parallel_linear\nE           from parallel_linear import RowParallelLinear\nE       ModuleNotFoundError: No module named 'parallel_linear'\n\n/root/.cache/uv/archive-v0/aTZRZY5bLGLtE1YxwfdWP/lib/python3.13/site-packages/torch/multiprocessing/spawn.py:215: ProcessRaisedException",
                "message": "The test failed in the call phase due to an exception"
            }
        ]
    }
}